{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\") # clearing cache \n",
    "libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Image Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Image classification is a common task for deep learning and neural networks.  The raw features coming in are the pixel values.  These are simple enough to deal with, but it is difficult to connect pixel values to determining whether an image is of a cat.  Older methods used a lot of clever filters, but the current best-of-breed algorithms simply throw a lot of linear algebra at the problem.\n",
    "\n",
    "In this miniproject, you build a series of models to classify a series of images into one of ten classes. For expediency, these images are pretty small ($32\\times32\\times3$).  This can make classification a bit tricky&mdash;human performance is only about 94%.  Each of your models will be scored by comparing its accuracy to the accuracy of a reference model that we developed.  A score of 1 indicates that your model performs as well as the reference model; not that your accuracy is 100%!\n",
    "\n",
    "You will be given both a training set and a validation set.  Ground truth values are provided for the training set.  You should train your models on this set, and then make predictions for each of the validation images.  These predictions will be submitted to the grader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## A note on scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "It **is** possible to score above 1 on these questions. This indicates that you've beaten our reference model&mdash;we compare our model's score on a test set to your score on a test set. See how high you can go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We will be using the `CIFAR-10` data set.  It consists of 60,000 images, each $32\\times32$ color pixels, each belonging to one of ten classes.  The following cell will download the data, in NumPy's `.npy` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "!aws s3 sync s3://dataincubator-course/cifar10/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We can load in the data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "train_images = np.load(gzip.open('train_images.npy.gz', 'rb'))\n",
    "train_labels = np.load(gzip.open('train_labels.npy.gz', 'rb'))\n",
    "validation_images = np.load(gzip.open('validation_images.npy.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The images are stored as four-dimensional arrays.  The first index indicates the image number, the second and third the $x$ and $y$ positions, and the fourth index the color channel.  Each pixel color is a floating point number between 0 and 1.  This convention allows us to view the images with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.reshape(50000,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1534a53a90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.rcParams[\"axes.grid\"] = False  #  Remove the grid lines from the image.\n",
    "matplotlib.pyplot.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The classes have already been numbered 0-9 for us; those numbers are stored in the vector `train_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The human-readable names associated with this classes are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names[train_labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Perceptual Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Since we already have a number of labeled images, a simple approach would be to measure the difference between two images, and choose the label corresponding to nearby images.  To do this, we need to develop a metric to determine the distance between two images.  We'll make the simplifying (and completely wrong) assumption that this is just the average difference between the colors of the corresponding pixels in the two images.\n",
    "\n",
    "While we could just take RMS difference of the red, green, and blue pixels, let's be slightly more sophisticated and look at human vision for a metric.  After all, we're pretty good at image classifications, so there might be some useful optimization here.\n",
    "\n",
    "It turns out that modeling human perception is [extraordinarily complicated](https://en.wikipedia.org/wiki/Color_difference#CIEDE2000).  We're going to use a [simplified model](https://www.compuphase.com/cmetric.htm):\n",
    "\n",
    "$$\\Delta C \\equiv \\sqrt{2 \\Delta R^2 + 4 \\Delta G^2 + 3 \\Delta B^2 + \\bar R\\left(\\Delta R^2 - \\Delta B^2 \\right)} $$\n",
    "where $(R_1, G_1, B_1)$ and $(R_2, G_2, B_2)$ are the RGB components of the two colors and\n",
    "$$\\begin{align}\n",
    "\\Delta R &= R_1 - R_2 \\\\\n",
    "\\Delta G &= G_1 - G_2 \\\\\n",
    "\\Delta B &= B_1 - B_2 \\\\\n",
    "\\bar R &= \\textstyle\\frac{1}{2}\\left(R_1 + R_2\\right)\n",
    "\\end{align}$$\n",
    "\n",
    "This accounts for the fact that our eyes are most sensitive to green and least sensitive to red, and that perception is not constant with hue.\n",
    "\n",
    "Build a graph that takes in a series of images, as well as a base image, and returns a result containing the $\\Delta C$ value (for each pixel) between the base image and each image in the series.  \n",
    "\n",
    "(Note that the intention here in our solution is that `images` will be a stack of images, while `base` is a single image.  Since the function is decorated with `tf.function` the computations within the function will be recorded in a computation graph and the output from this function will be a tensor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "   \n",
    "\n",
    "@tf.function\n",
    "def c_delta(m,n):\n",
    "    r_2 = tf.square(tf.subtract(m[:,:,0], n[:,:,0]))\n",
    "    g_2 = tf.square(tf.subtract(m[:,:,1], n[:,:,1]))\n",
    "    b_2 = tf.square(tf.subtract(m[:,:,2], n[:,:,2]))\n",
    "    r_bar = tf.divide(tf.add(m[:,:,0], n[:,:,0]),2)\n",
    "    c_delta = tf.sqrt(2*r_2 + 4*g_2 + 3*b_2 + r_bar*(r_2-b_2))\n",
    "    return tf.reduce_sum(c_delta)/(32*32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "As stated, for two images, $I_1$ and $I_2$, we define the distance between $I_1$ and $I_2$ as the average $\\Delta C$ value over the whole image, that is:\n",
    "\n",
    "$$d(I_1, I_2) = \\frac{1}{N}\\sum_{p_j} \\Delta C(p_j)$$\n",
    "where the sum is over all pixels $p_j$, $\\Delta C(p_2)$ is the $\\Delta C$ value for the pixel $p_j$, and $N$ is the total number of pixels in each image ($N= 32\\times 32$ in our case).\n",
    "\n",
    "Using `delta_func` compute the distance between the first validation image and all of the training images.\n",
    "\n",
    "**Checkpoint:** The mean value of the distances is 1.159, and the standard deviation of the distances is 0.182."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def delta_func(images, base):\n",
    "    return tf.map_fn(lambda x: c_delta(x,base),images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "deltas = delta_func(train_images, validation_images[0])\n",
    "nums = deltas.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "From these, find the 100 closest images from the training set to this first validation image.  (Note that `numpy.argsort` might help here.)  Submit a list of the indices of these images to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nums' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnums\u001b[49m\u001b[38;5;241m.\u001b[39margsort()[:\u001b[38;5;241m100\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nums' is not defined"
     ]
    }
   ],
   "source": [
    "indices = list(nums.argsort()[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "**Extension:** What does this suggest about the proper class for this image?\n",
    "\n",
    "> **Aside:** Essentially, we've started to implement a $k$-nearest neighbors algorithm, using this perceptual distance as our metric.  If we ran the difference between all of the validation images and each of the training images, we could make a prediction from the nearest images for each.  Give it a try, if you're interested, but this miniproject is going to go in another direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Softmax model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We could use this delta function to measure distances from images with known classes, but that's not really the Deep Learning Way (TM).  Instead, we'll let neural networks figure out how to connect pixel values to classes.\n",
    "\n",
    "We'll start with something that barely qualifies as a neural network: a softmax classifier.  This has no hidden layers; instead a single dense layer takes $32\\times32\\times3$ inputs and produces 10 outputs, one for each class.  It should use a softmax activation and a `CategoricalCrossentropy` loss function.\n",
    "\n",
    "Build such a model and train it on the training data.  Then use this model to make a prediction on each of the 10,000 validation images.\n",
    "\n",
    "**Hints:**\n",
    "- The labels are given as integers, but softmax expects one-hot encoding of the labels.  The `tf.one_hot` function can do the conversion.\n",
    "- TensorFlow's `.predict` method will return probabilities for each image being in each class, but the grader wants only the class prediction.  You may find the `np.argmax` function helpful in determining the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "#     tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "              \n",
    "#               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(train_labels, 10).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.9597 - accuracy: 0.3162\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8868 - accuracy: 0.3498\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8544 - accuracy: 0.3639\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8448 - accuracy: 0.3676\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8343 - accuracy: 0.3726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f0799fa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(train_images, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                30730     \n",
      "=================================================================\n",
      "Total params: 30,730\n",
      "Trainable params: 30,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(model.predict(validation_images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpredicted_classes\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_classes' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_classes = list(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Fully-connected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, add a hidden layer to this network.  Train this network on the pixel values, and once again use it to predict the most likely class for each of the validation images.\n",
    "\n",
    "**Hints:**\n",
    "- We found that adding more layers didn't help too much.\n",
    "- Watch out for overfitting.  Dropout can help with this.\n",
    "- The reference solution achieves an accuracy of about 44% on a training set and 41% on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Dense(3072, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "#     tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "              \n",
    "#               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.9506 - accuracy: 0.3093\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7803 - accuracy: 0.3596\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7365 - accuracy: 0.3768\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.7103 - accuracy: 0.3876\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6918 - accuracy: 0.3975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f003d520>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_images, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3072)              9440256   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                30730     \n",
      "=================================================================\n",
      "Total params: 9,470,986\n",
      "Trainable params: 9,470,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(model_2.predict(validation_images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpredicted_classes\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_classes' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_classes = list(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Convolutional model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Convolutional neural networks have had a lot of success in image classification.  Build a neural network with convolutional layers to improve the performance.\n",
    "\n",
    "**Hints:**\n",
    "- The reference solution uses two convolutional layers and two fully-connected layers.\n",
    "- We found success with the `AdamOptimizer`.\n",
    "- The reference solution achieves an accuracy of roughly 80% on a training set and 70% on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "n_classes = 10\n",
    "n_channels = 3\n",
    "filt_size = [8, 8] # 5x5 pixel filters\n",
    "\n",
    "batch_size = 50\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = keras.models.Sequential()\n",
    "\n",
    "model_cnn.add(keras.layers.Reshape([img_size, img_size, n_channels]))\n",
    "model_cnn.add(keras.layers.Conv2D(32, (3, 3), padding='same',\n",
    "                              activation='relu'))\n",
    "\n",
    "model_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),\n",
    "                                    padding='same'))\n",
    "\n",
    "model_cnn.add(keras.layers.Conv2D(64, (3, 3), padding='same',\n",
    "                              activation='relu'))\n",
    "\n",
    "model_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),\n",
    "                                    padding='same'))\n",
    "\n",
    "# model_cnn.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_cnn.add(keras.layers.Flatten())\n",
    "\n",
    "model_cnn.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "model_cnn.add(keras.layers.Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 1.3913 - accuracy: 0.5061\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.0409 - accuracy: 0.6371\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.9124 - accuracy: 0.6828\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.8275 - accuracy: 0.7106\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.7566 - accuracy: 0.7367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe31849db80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(train_images, y_train, epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (50, 32, 32, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (50, 32, 32, 32)          896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (50, 16, 16, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (50, 16, 16, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (50, 8, 8, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (50, 4096)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (50, 100)                 409700    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (50, 10)                  1010      \n",
      "=================================================================\n",
      "Total params: 430,102\n",
      "Trainable params: 430,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(model_cnn.predict(validation_images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpredicted_classes\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_classes' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_classes = list(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "In transfer learning, we use a network trained on one data set to provide a starting point for the modeling of other data.  As we are trying to model color images, we should look for another network trained on color images.  Luckily, we have already discussed such a network: the Inception network used in the Deep Dream notebook.\n",
    "\n",
    "The following cell will load the model, omitting its classification layer (since we're not interested in classifying `ImageNet` images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# include_top=False will discard avg_pool before prediction layer\n",
    "inception = tf.keras.applications.inception_v3.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "inception = tf.keras.Model([inception.input], [inception.layers[-2].output]) # manually discard prediction layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "In a transfer learning setup, we will use the first part of the trained network to process the original images, and then train a network to make predictions from the output of the trained network.  There are several ways to accomplish this.\n",
    "\n",
    "One approach is to connect the new layers to the output of the existing layers.  Data will flow through the pre-trained layers as well as those added.  In the training step, only the new layers should be marked as trainable.\n",
    "\n",
    "However, this can be a bit wasteful when multiple epochs of training will be undertaken since we recalculate the latent vectors on every training step.  With a smaller data set, such as this, it can be more efficient to pre-calculate the *latent vectors* that are the output of the pre-trained network.  These can be stored and used as input for training a smaller, separate network to make the predictions.  We recommend this approach for this miniproject.\n",
    "\n",
    "Images should be fed to the `inception` network and then vectorized (you might want to refer to the `TF_DeepDream.ipynb` notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We've loaded the `inception` network with its native image shape: $299 \\times 299$.  This implies that we need to upscale our images from $32\\times32$ to $299\\times299$.  There are a number of ways to do this; the reference solution uses `tf.image.resize` with bilinear interpolation.  (More sophisticated resizing methods produce better results, but will take significantly longer!)\n",
    "\n",
    "It may make sense to do the rescaling and latent vector calculation at the same time, to avoid storing the (somewhat large) rescaled images unnecessarily.  You also probably want to save those latent vectors to disk, to avoid the need to repeat this calculation later.\n",
    "\n",
    "**Hints:**\n",
    "- Be sure to batch this calculation; resizing all 50,000 images at once will cause memory errors.\n",
    "- The latent vector calculation took us between 30 minutes and 2 hours on a single machine.  You might consider distributing the calculation.\n",
    "- The latent vectors for the first 10 images have an average of 1983 non-zero values and an overall average value of 0.319."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "With the latent vectors calculated, we can use them as input to train a small neural network to make the final predictions.\n",
    "\n",
    "**Hints:**\n",
    "- The reference solution has three layers.\n",
    "- The reference solution achieves a training accuracy of 87% and a test accuracy of 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "\n",
    "# for batch in range(50):\n",
    "#     train_subset = train_images[(batch * 1000):(batch + 1) * 1000]\n",
    "#     resized_images = tf.image.resize(train_subset,[299, 299])\n",
    "#     inception_pred = inception.predict(resized_images)\n",
    "#     with open('batch_{}.npy'.format(batch), 'wb') as f:\n",
    "#         np.save(f, inception_pred)\n",
    "# #     np.save(f\"batch_{batch}\", arr_to_save)\n",
    "#     del inception_pred\n",
    "#     del resized_images\n",
    "#     del train_subset\n",
    "#     gc.collect()\n",
    "#     libc.malloc_trim(0)\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in range(10):\n",
    "#     val_subset = validation_images[(batch * 1000):(batch + 1) * 1000]\n",
    "#     resized_images = tf.image.resize(val_subset,[299, 299])\n",
    "#     inception_pred = inception.predict(resized_images)\n",
    "#     with open('val_batch_{}.npy'.format(batch), 'wb') as f:\n",
    "#         np.save(f, inception_pred)\n",
    "# #     np.save(f\"val_batch_{batch}\", arr_to_save)\n",
    "#     del inception_pred\n",
    "#     del resized_images\n",
    "#     del val_subset\n",
    "#     gc.collect()\n",
    "#     libc.malloc_trim(0)\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all files together\n",
    "train_latent = None\n",
    "for batch in range(50):\n",
    "    a = np.load(open(\"batch_{}.npy\".format(batch),'rb'))\n",
    "    if train_latent is None:\n",
    "        train_latent = a\n",
    "    else:\n",
    "        train_latent = np.concatenate((train_latent, a), axis=0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vali files together\n",
    "validation_latent = None\n",
    "for batch in range(10):\n",
    "    b = np.load(open(\"val_batch_{}.npy\".format(batch),'rb'))\n",
    "    if validation_latent is None:\n",
    "        validation_latent = b\n",
    "    else:\n",
    "        validation_latent = np.concatenate((validation_latent, b), axis=0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1667909 , 0.04119096, 0.21842594, ..., 0.19361416, 0.18005972,\n",
       "       0.04173461], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_subset = validation_images[0:10]\n",
    "resized_images = tf.image.resize(val_subset,[299, 299])\n",
    "inception_pred = inception.predict(resized_images)\n",
    "inception_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = train_labels[:48000]\n",
    "\n",
    "X_train = train_latent[:48000]\n",
    "\n",
    "X_test = train_latent[48000:]\n",
    "y_test = train_labels[48000:]\n",
    "                          \n",
    "from tensorflow.keras.utils import to_categorical as one_hot\n",
    "\n",
    "y_train_hot = one_hot(y_train)\n",
    "y_test_hot = one_hot(y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PIXELS= 299 * 299 * 3\n",
    "N_CLASSES = 10\n",
    "\n",
    "n_epochs = 10\n",
    "hidden_size = 64\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        hidden_size,\n",
    "        activation='sigmoid',\n",
    "        use_bias=True,  # The default\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(stddev=N_PIXELS**-0.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        activation='softmax',\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(stddev=hidden_size**-0.5)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=0.5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7857 - accuracy: 0.7332 - val_loss: 0.5185 - val_accuracy: 0.8315\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.8190 - val_loss: 0.5166 - val_accuracy: 0.8240\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.8351 - val_loss: 0.4592 - val_accuracy: 0.8505\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4375 - accuracy: 0.8475 - val_loss: 0.4496 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4161 - accuracy: 0.8542 - val_loss: 0.4378 - val_accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8614 - val_loss: 0.4232 - val_accuracy: 0.8530\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8655 - val_loss: 0.4539 - val_accuracy: 0.8380\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8711 - val_loss: 0.4655 - val_accuracy: 0.8435\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8759 - val_loss: 0.4372 - val_accuracy: 0.8475\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8794 - val_loss: 0.4128 - val_accuracy: 0.8585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f151c3349d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_hot,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_test,y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(model.predict(validation_latent),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mpredicted_classes\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_classes' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_classes = list(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "*Copyright &copy; 2021 Pragmatic Institute. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbclean": true,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
